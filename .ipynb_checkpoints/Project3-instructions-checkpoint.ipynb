{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: POS tagging with the Perceptron algorithm\n",
    "\n",
    "COSI 134 Fall 2019\n",
    "  \n",
    "Due: November 15, 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task definition. \n",
    "\n",
    "POS tagging is the task of assigning a POS tag to each word token in the sentence.\n",
    "\n",
    "As with all supervised learning approaches to POS tagging, this task has two parts. The first part is the decoding problem: given trained model parameters, you asked to write code to find the best tagging sequence given the word tokens in a sequence and the model parameters. For this you need to implement the Viterbi algorithm. The second part is the training algorithm, which takes a annotated training set and outputs a set of model parameters. For this, you are asked to implement the Perception algorithm. The Perceptron algorithm is simple yet effective. It has known to produce results that are at or close to the state of the art. If you implement the learning and decoding algorithms correctly, you will end up with a usable POS tagger that is not far off from the state of the art.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will be using the standard train / development / test split in the Penn TreeBank for our experiments: Sections 02-21 are used for training, Section 22 is used for devevelopment, and Section 23 is used as the test set. You can use the development set to select the features and tune the hyperparameters, but you can only run your model on the test set only once after you have a fully tuned model. \n",
    "\n",
    "The data format is very straightforward: each line of the data file contains one sentence. The annotated gold standard data is in the form of \n",
    "$word_1\\_pos_1$ $word_2\\_pos_2$ $\\cdots$  $word_n\\_pos_n$\n",
    "For the training and dev data, you are provided with the sentences with their gold POS tags. For test data, you are only given the word tokens. The TAs will run your code on the test set to get the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "You are asked to run a number of experiments to help you understand the behavior of the Perceptron algorithm. You can run these experiments on your development set.\n",
    "\n",
    "### Perceptron vs Averaged perceptron\n",
    "\n",
    "Test your model on the development set using both the Perceptron model and Averaged Perceptron model, and observe if there is any difference in performance.\n",
    "\n",
    "### Ablation study on features\n",
    "\n",
    "Test your model on different feature sets. As we have discussed in class, state of the art models use a five-word window centered on the current word at each position in the sentence:\n",
    " - `Current word:` $word_0$\n",
    " - `Previous words:` $word_-1$, $word_-2$\n",
    " - `Next words:` $word_1, word_2$ \n",
    " - `Tag of previous word:` $pos_-1$\n",
    " - `Prefix and suffix of current word`\n",
    " \n",
    "When you do your ablation study, first run an experiment with the full set of features. Next take out each feature group at a time and observe the change in accuracy.\n",
    "\n",
    "## Implementation details\n",
    "\n",
    " - With a large feature space, if it is implemented as a feature vector, it will be very sparse. As such it may not be the most efficient approach. One alternative is to implement the feature weights as a dictionary that is only updated for features that fire for a given training instance.\n",
    " - The core Perceptron learning algorithm and the Viterbi decoding algorithm should be implemented in `perceptron pos tagger.py`\n",
    " - The experiments can be encoded in `train test tagger.py`. Make sure you tag the test set with your tagger and write it to a file that has the same format as the training data.\n",
    " - Feel free to add new classes, functions, methods or modules to the starter code, or modify it as you see fit.\n",
    " \n",
    "## Report\n",
    "\n",
    "Write a report that  a) briefly describe the structure of your code, b) present your experimental settings and results, and c) any insights that you have learned from your experiments. Your report should be no longer than 3 pages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
